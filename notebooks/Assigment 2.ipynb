{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation on Edgar filings\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this assignment is to extract valuable information from text and convert it into variables where the initial input is a list of companies in a dataset, the idea will be to reproduce into certain extent what is revised in the notebooks 2.1, 2.2 as well as taking in consideration the block 1 which objective will be to augment/create knowledge of each company/entry.\n",
    "\n",
    "The following assignment is divided into 3 parts: Text features creations, Dataset augmentation and Exploratory analysis on text features where is each part will be asked to create functions or routines for data processing.  \n",
    "\n",
    "The expected output of this notebook is a rich, structured data in table format as well as exporatory analysis:\n",
    "\n",
    "1. **Core Dataset** - Table formated data ready for analytics\n",
    "2. **Analysis** - Be creative!! here you have the freedom to perform any data analysis of your preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDGAR filings text analysis links [Github repo](https://github.com/rohitharitash/EDGAR-reports-Text-Analysis), [OpenEDGAR paper](https://arxiv.org/pdf/1806.04973.pdf) and [Code](https://github.com/LexPredict/openedgar) as complementary resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Text features creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a function or procedure that perform the NLP tasks revised in Section 2.2.1. (Stopwords adding, Stemming, Tokenization, etc.) feel free to add additional steps found in different resources. We will use the EDGAR corpus.\n",
    "```python\n",
    "'pickle/EDGAR_corpus.pkl'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the function `read_dictionary` revised on 2.2.1 to read the dictionaries:\n",
    "    - positive_words.txt\n",
    "    - negative_words.txt\n",
    "    - uncertainty_dictionary.txt\n",
    "    - constraining_dictionary.txt\n",
    "    \n",
    "Importing the file `sentiment_scores.py` as a library calculate the respective scores. Do not forget that this module uses `nltk`\n",
    "```python\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a formula or method that calculate the relative scores:  $\\frac{absoluteScore}{wordsReport}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test all the functions created on one text/report, example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "positive_score = generate_score(report, positive_words)\n",
    "negative_score = generate_score(report, negative_words)\n",
    "count_tokens = total_word_count(report)\n",
    "polarity = polarity_score(positive_score, negative_score)\n",
    "uncertainty_score = generate_score(report, uncertainty_dict)\n",
    "constraining_score = generate_score(report, constraining_dict)\n",
    "avg_sentence_length = average_sentence_length(report)\n",
    "perc_complex_word = percentage_complex_word(report)\n",
    "fog_index = calculate_fog_index(avg_sentence_length, perc_complex_word)\n",
    "positive_relative = relative_score(positive_score, count_tokens)\n",
    "negative_relative = relative_score(negative_score, count_tokens)\n",
    "uncertainty_relative = relative_score(uncertainty_score, count_tokens)\n",
    "constraining_relative = relative_score(constraining_score, count_tokens)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Dataset augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Apply that function to each report in `EDGAR_corpus.pkl` and update the text for each company   \n",
    "**IMPORTANT: try for a small number of companies (say 5) since the process might take time to compute** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Using the procedure created in Section 1.4.3 and add the risk-loss features to our core dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create a relative **risk** score as follows: $\\frac{wordsRisk+wordsLoss}{wordsReport}$ add the score to the core table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Save the final table, the columns should look more or less like this:\n",
    "```python\n",
    "['company_name', 'count_tokens', 'average_sentence_length',\n",
    "       'percentage_complex_word', 'positive_score', 'negative_score',\n",
    "       'uncertainty_score', 'constraining_score', 'relative_positive',\n",
    "       'relative_negative', 'relative_uncertainty', 'fog_index',\n",
    "       'relative_constraining', 'risk_loss', 'relative_risk']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Exploratory analysis on text features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. With the dataset clean and ready, conduct an exploratory data analysis, there are no rules neither recipies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get some inspiration from [towardsdatascience.com](https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a) and [zablo.net](https://zablo.net/blog/post/twitter-sentiment-analysis-python-scikit-word2vec-nltk-xgboost/index.html) (also original [repo](https://github.com/marrrcin/ml-twitter-sentiment-analysis/blob/develop/twitter_sentiment_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
