{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### PGGM Bootcamp Text Analytics 2020\n",
    "*Notebook by [Pedro V Hernandez Serrano](https://github.com/pedrohserrano)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "![](images/3_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Financial Sentiment Analysis\n",
    "* [3.1.1. Sentiment correlation](#3.1.1)\n",
    "* [3.1.2. Sentiment through the corpus](#3.1.2)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is a subfield within: \n",
    "- Textual analysis\n",
    "- Natural language processing\n",
    "- Content analysis\n",
    "- Computational linguistics\n",
    "\n",
    "Increased interest attributable to:\n",
    "- Bigger, faster computers → faster processing of data (HFTs)\n",
    "- Availability of large quantities of text → better interpretation of information\n",
    "- New technologies derived from search engines → improve quality of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some early financial sentiment analysis by [Paul C. Tetlock](https://www.jstor.org/stable/4622297?seq=1#metadata_info_tab_contents)\n",
    "![](images/paultetlock.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications  \n",
    "- Stock prediction is a concurrent application of text mining to give scores (financial sentiments) and trade\n",
    "- Automate news analysis: Contents and Tone, Measurement of qualitative and quantitative attributes\n",
    "- The dictionaries or lexicon is domain specific.\n",
    "- You have also events (predicates) we can say that is organization events, on an unsupervised approach, *See: [The Stock Sonar](https://pdfs.semanticscholar.org/a9b7/bf3e34c1a0235d07d423eb9d0c3b46c630e5.pdf)*\n",
    "- We have more applications and better interfaces, *See happines of the world [hedenometer](http://hedonometer.org/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1.1. Sentiment correlation\n",
    "<a id=\"3.1.1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **TextBlob package:** Linguistic researchers have labeled the sentiment of words based on their domain expertise. Sentiment of words can vary based on where it is in a sentence. The TextBlob package allows us to take advantage of these labels.\n",
    "2. **Sentiment Labels:** Each word in a corpus is labeled in terms of polarity and subjectivity, for the following example and we can define a corpus' sentiment ias the average of these.\n",
    "   * **Polarity**: How positive or negative a word is. -1 is very negative. +1 is very positive.\n",
    "   * **Subjectivity**: How subjective, or opinionated a word is. 0 is fact. +1 is very much an opinion.\n",
    "\n",
    "For more info on how `TextBlob` coded up its [sentiment function](https://planspace.org/20150607-textblob_sentiment/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('pickle/AnnualReports_corpus.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminal / Anaconda Navigator: conda install -c conda-forge textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "data['polarity'] = data['report'].apply(pol)\n",
    "data['subjectivity'] = data['report'].apply(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "\n",
    "for index, company in enumerate(data.index):\n",
    "    x = data.polarity.loc[company]\n",
    "    y = - data.subjectivity.loc[company]\n",
    "    plt.scatter(x, y, color='#008080', s=120, alpha=.8)\n",
    "    plt.text(x+.001, y+.001, data['company_name'][index], fontsize=8)\n",
    "    #plt.xlim(-.01, .12) \n",
    "    \n",
    "plt.title('Sentiment Analysis', fontsize=20)\n",
    "plt.xlabel('<-- Negative -------- Positive -->', fontsize=20)\n",
    "plt.ylabel('<-- Opinions -------- Facts -->', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1.2. Sentiment through the corpus\n",
    "<a id=\"3.1.2\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split each documents into 20 parts\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def split_text(text, n=20):\n",
    "    '''Takes in a string of text and splits into n equal parts, with a default of 10 equal parts.'''\n",
    "\n",
    "    # Calculate length of text, the size of each chunk of text and the starting points of each chunk of text\n",
    "    length = len(text)\n",
    "    size = math.floor(length / n)\n",
    "    start = np.arange(0, length, size)\n",
    "    \n",
    "    # Pull out equally sized pieces of text and put it into a list\n",
    "    split_list = []\n",
    "    for piece in range(n):\n",
    "        split_list.append(text[start[piece]:start[piece]+size])\n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a list to hold all of the pieces of text\n",
    "list_pieces = []\n",
    "for t in data.report:\n",
    "    split = split_text(t)\n",
    "    list_pieces.append(split)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list has 10 elements, one for each text\n",
    "len(list_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the polarity for each piece of text\n",
    "polarity_transcript = []\n",
    "for lp in list_pieces:\n",
    "    polarity_piece = []\n",
    "    for p in lp:\n",
    "        polarity_piece.append(TextBlob(p).sentiment.polarity)\n",
    "    polarity_transcript.append(polarity_piece)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the plot for all companies\n",
    "plt.rcParams['figure.figsize'] = [16, 20]\n",
    "\n",
    "for index, company in enumerate(data.index):    \n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.plot(polarity_transcript[index])\n",
    "    plt.plot(np.arange(0,20), np.zeros(20))\n",
    "    plt.title(data['company_name'][index])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### *Learn more about applications on this [Youtube video](https://www.youtube.com/watch?v=QXlCAFPtmbg): Techniques and Applications for Sentiment Analysis at 5th Annual Wolfram Data Summit 2014*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
