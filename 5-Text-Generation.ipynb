{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains can be used for very basic text generation. Think about every word in a corpus as a state. We can make a simple assumption that the next word is only dependent on the previous word - which is the basic assumption of a Markov chain.\n",
    "\n",
    "Markov chains don't generate text as well as deep learning, but it's a good (and fun!) start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Text to Imitate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're specifically going to generate text in the style of Ali Wong, so as a first step, let's extract the text from her comedy routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABN_AMRO_Group_(2018)</th>\n",
       "      <td>babn amro bank nvabn amro group nv annual repo...</td>\n",
       "      <td>ABN_AMRO_Group_(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGNC_Investment_(2018).pdf</th>\n",
       "      <td>bproviding private capital to the us housing m...</td>\n",
       "      <td>AGNC_Investment_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acer_(2018).pdf</th>\n",
       "      <td>bacer  annual reportnnpublication date  april ...</td>\n",
       "      <td>Acer_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autohome_(2018).pdf</th>\n",
       "      <td>btable of contentsnn n nn nn nnunited statesnn...</td>\n",
       "      <td>Autohome_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAIC_Motor_Corporation_(2018).pdf</th>\n",
       "      <td>ba joint stock company incorporated in the  re...</td>\n",
       "      <td>BAIC_Motor_Corporation_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carlsberg_(2018).pdf</th>\n",
       "      <td>nreview nn nnfinancial  nstatements nncarlsbe...</td>\n",
       "      <td>Carlsberg_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_Brothers_Group_(2018).pdf</th>\n",
       "      <td>bmodern merchant bankingnnclose brothers group...</td>\n",
       "      <td>Close_Brothers_Group_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deutsche_Bank_(2018).pdf</th>\n",
       "      <td>bdeutsche banknn annual report  banknnthe grou...</td>\n",
       "      <td>Deutsche_Bank_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edison_International_(2018).pdf</th>\n",
       "      <td>walnut grove avenuenrosemead ca  ninnnntnenrn...</td>\n",
       "      <td>Edison_International_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genworth_Mortgage_Insurance_Australia_(2018).pdf</th>\n",
       "      <td>nannual nreportnnillustration by naustralian ...</td>\n",
       "      <td>Genworth_Mortgage_Insurance_Australia_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCP_(2018).pdf</th>\n",
       "      <td>bsky ridge nmedical office nlone tree co    nn...</td>\n",
       "      <td>HCP_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan_Post_Bank_(2018).pdf</th>\n",
       "      <td>bannual report  ended march   nphilosophynnjap...</td>\n",
       "      <td>Japan_Post_Bank_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lynas_(2018).pdf</th>\n",
       "      <td>nannual   from the chairman nnceo review nnc...</td>\n",
       "      <td>Lynas_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marston's_(2018).pdf</th>\n",
       "      <td>bmaking  n  nthe place to be  plc n  nnannual ...</td>\n",
       "      <td>Marston's_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitsubishi_Materials_Corporation_(2018).pdf</th>\n",
       "      <td>to our stakeholders                         ...</td>\n",
       "      <td>Mitsubishi_Materials_Corporation_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modern_Times_Group_(2018).pdf</th>\n",
       "      <td>bannual report  a glancenn  salesnneur   on a ...</td>\n",
       "      <td>Modern_Times_Group_(2018).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promotora_y_Operadora_de_Infraestructura_(2018).pdf</th>\n",
       "      <td>b nn n nn nn n nn nnpromotora y operadora de i...</td>\n",
       "      <td>Promotora_y_Operadora_de_Infraestructura_(2018...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               report  \\\n",
       "ABN_AMRO_Group_(2018)                               babn amro bank nvabn amro group nv annual repo...   \n",
       "AGNC_Investment_(2018).pdf                          bproviding private capital to the us housing m...   \n",
       "Acer_(2018).pdf                                     bacer  annual reportnnpublication date  april ...   \n",
       "Autohome_(2018).pdf                                 btable of contentsnn n nn nn nnunited statesnn...   \n",
       "BAIC_Motor_Corporation_(2018).pdf                   ba joint stock company incorporated in the  re...   \n",
       "Carlsberg_(2018).pdf                                 nreview nn nnfinancial  nstatements nncarlsbe...   \n",
       "Close_Brothers_Group_(2018).pdf                     bmodern merchant bankingnnclose brothers group...   \n",
       "Deutsche_Bank_(2018).pdf                            bdeutsche banknn annual report  banknnthe grou...   \n",
       "Edison_International_(2018).pdf                      walnut grove avenuenrosemead ca  ninnnntnenrn...   \n",
       "Genworth_Mortgage_Insurance_Australia_(2018).pdf     nannual nreportnnillustration by naustralian ...   \n",
       "HCP_(2018).pdf                                      bsky ridge nmedical office nlone tree co    nn...   \n",
       "Japan_Post_Bank_(2018).pdf                          bannual report  ended march   nphilosophynnjap...   \n",
       "Lynas_(2018).pdf                                      nannual   from the chairman nnceo review nnc...   \n",
       "Marston's_(2018).pdf                                bmaking  n  nthe place to be  plc n  nnannual ...   \n",
       "Mitsubishi_Materials_Corporation_(2018).pdf           to our stakeholders                         ...   \n",
       "Modern_Times_Group_(2018).pdf                       bannual report  a glancenn  salesnneur   on a ...   \n",
       "Promotora_y_Operadora_de_Infraestructura_(2018)...  b nn n nn nn n nn nnpromotora y operadora de i...   \n",
       "\n",
       "                                                                                         company_name  \n",
       "ABN_AMRO_Group_(2018)                                                           ABN_AMRO_Group_(2018)  \n",
       "AGNC_Investment_(2018).pdf                                                 AGNC_Investment_(2018).pdf  \n",
       "Acer_(2018).pdf                                                                       Acer_(2018).pdf  \n",
       "Autohome_(2018).pdf                                                               Autohome_(2018).pdf  \n",
       "BAIC_Motor_Corporation_(2018).pdf                                   BAIC_Motor_Corporation_(2018).pdf  \n",
       "Carlsberg_(2018).pdf                                                             Carlsberg_(2018).pdf  \n",
       "Close_Brothers_Group_(2018).pdf                                       Close_Brothers_Group_(2018).pdf  \n",
       "Deutsche_Bank_(2018).pdf                                                     Deutsche_Bank_(2018).pdf  \n",
       "Edison_International_(2018).pdf                                       Edison_International_(2018).pdf  \n",
       "Genworth_Mortgage_Insurance_Australia_(2018).pdf     Genworth_Mortgage_Insurance_Australia_(2018).pdf  \n",
       "HCP_(2018).pdf                                                                         HCP_(2018).pdf  \n",
       "Japan_Post_Bank_(2018).pdf                                                 Japan_Post_Bank_(2018).pdf  \n",
       "Lynas_(2018).pdf                                                                     Lynas_(2018).pdf  \n",
       "Marston's_(2018).pdf                                                             Marston's_(2018).pdf  \n",
       "Mitsubishi_Materials_Corporation_(2018).pdf               Mitsubishi_Materials_Corporation_(2018).pdf  \n",
       "Modern_Times_Group_(2018).pdf                                           Modern_Times_Group_(2018).pdf  \n",
       "Promotora_y_Operadora_de_Infraestructura_(2018)...  Promotora_y_Operadora_de_Infraestructura_(2018...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the corpus, including punctuation!\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('pickle/corpus_AnnualR.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bdeutsche banknn annual report  banknnthe group at a glancennkey financial informationnposttax return on average  equitynposttax return on average tangible  equityncostincome    net revenues in  mnpro'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract only Deutsche_Bank_(2018) text\n",
    "_text = data.report.loc['Deutsche_Bank_(2018).pdf']\n",
    "_text[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Markov Chain Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build a simple Markov chain function that creates a dictionary:\n",
    "* The keys should be all of the words in the corpus\n",
    "* The values should be a list of the words that follow the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def markov_chain(text):\n",
    "    '''The input is a string of text and the output will be a dictionary with each word as\n",
    "       a key and each value as the list of words that come after the key in the text.'''\n",
    "    \n",
    "    # Tokenize the text by word, though including punctuation\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    # Initialize a default dictionary to hold all of the words and next words\n",
    "    m_dict = defaultdict(list)\n",
    "    \n",
    "    # Create a zipped list of all of the word pairs and put them in word: list of next words format\n",
    "    for current_word, next_word in zip(words[0:-1], words[1:]):\n",
    "        m_dict[current_word].append(next_word)\n",
    "\n",
    "    # Convert the default dict back into a dictionary\n",
    "    m_dict = dict(m_dict)\n",
    "    return m_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary for deutsche report, take a look at it\n",
    "_dict = markov_chain(_text)\n",
    "#_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create a function that generates sentences. It will take two things as inputs:\n",
    "* The dictionary you just created\n",
    "* The number of words you want generated\n",
    "\n",
    "Here are some examples of generated sentences:\n",
    "\n",
    ">'Shape right turn– I also takes so that she’s got women all know that snail-trail.'\n",
    "\n",
    ">'Optimum level of early retirement, and be sure all the following Tuesday… because it’s too.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_sentence(chain, count=15):\n",
    "    '''Input a dictionary in the format of key = current word, value = list of next words\n",
    "       along with the number of words you would like to see in your generated sentence.'''\n",
    "\n",
    "    # Capitalize the first word\n",
    "    word1 = random.choice(list(chain.keys()))\n",
    "    sentence = word1.capitalize()\n",
    "\n",
    "    # Generate the second word from the value list. Set the new word as the first word. Repeat.\n",
    "    for i in range(count-1):\n",
    "        word2 = random.choice(chain[word1])\n",
    "        word1 = word2\n",
    "        sentence += ' ' + word2\n",
    "\n",
    "    # End it with a period\n",
    "    sentence += '.'\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ofnregions and did see  to  exposures exceeding us to claim and size   perndecember  outside the regular limit frameworknna major business activities generate risks are focusing.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(_dict, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
