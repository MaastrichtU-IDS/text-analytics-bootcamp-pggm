{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### PGGM Bootcamp Text Analytics 2020\n",
    "*Notebook by [Pedro V Hernandez Serrano](https://github.com/pedrohserrano)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "![](images/4_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Text Similarity\n",
    "* [4.1.1. Text distance algorithms](#3.2.1)\n",
    "* [4.1.2. Vectorization](#3.2.2)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring how ‘close’ two pieces of text are both in surface closeness [lexical similarity] and meaning [semantic similarity].  \n",
    "\n",
    "For instance, how similar are the phrases “the cat ate the mouse” with “the mouse ate the cat food” by just looking at the words?\n",
    "On the surface, if you consider only word level similarity, these two phrases appear very similar as 3 of the 4 unique words are an exact overlap. It typically does not take into account the actual meaning behind words or the entire phrase in context.\n",
    "\n",
    "Instead of doing a word for word comparison, we also need to pay attention to context in order to capture more of the semantics. To consider semantic similarity we need to focus on phrase/paragraph levels (or lexical chain level) where a piece of text is broken into a relevant group of related words prior to computing similarity. We know that while the words significantly overlap, these two phrases actually have different meaning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.1.1. Text distance algorithms\n",
    "<a id=\"4.1.1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"I am a man. She is a woman.\"\n",
    "str2 = \"\"\"Case C-40/08\n",
    "(Directive 93/13/EEC – Consumer contracts – Unfair arbitration clause – Measure void – Arbitration award which has become final – Enforcement – Whether the national court responsible for enforcement can consider of its own motion whether the unfair arbitration clause is null and void – Principles of equivalence and effectiveness)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(str1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "print(get_jaccard_sim(str1,str2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('pickle/EDGAR_matrix.pkl')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company1 = 'ADK'\n",
    "all_tokens1 = data.loc[company1,:]\n",
    "tokens1 = [i for i, j in zip(all_tokens1.index, all_tokens1) if j > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company2 = 'BLFS'\n",
    "all_tokens2 = data.loc[company2,:]\n",
    "tokens2 = [i for i, j in zip(all_tokens2.index, all_tokens2) if j > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distances'\n",
    ",textdistance.jaccard(tokens1 , tokens2)\n",
    ",textdistance.hamming(tokens1 , tokens2)\n",
    ",textdistance.hamming.distance(tokens1 , tokens2)\n",
    ",textdistance.hamming.similarity(tokens1 , tokens2) #same\n",
    ",textdistance.hamming.normalized_distance(tokens1 , tokens2)\n",
    ",textdistance.hamming.normalized_similarity(tokens1 , tokens2)\n",
    ",textdistance.Hamming(qval=2).distance(tokens1 , tokens2)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distances',\n",
    "textdistance.cosine.distance(tokens1 , tokens2),\n",
    "textdistance.cosine.normalized_distance(tokens1 , tokens2),\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(textdistance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### *Check the textdistance [documentation](https://github.com/life4/textdistance)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar_data = pd.read_csv('data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard = 'ADK'\n",
    "bag_ow = data.loc[gold_standard,:]\n",
    "gold_standard_tokens = [i for i, j in zip(bag_ow.index, bag_ow) if j > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_distance = []\n",
    "for company in data.index:\n",
    "    bag = data.loc[company,:]\n",
    "    tokens = [i for i, j in zip(bag.index, bag) if j > 0]\n",
    "    cosine_distance.append(textdistance.lcsseq.distance(gold_standard_tokens , tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar_data['cosine_distance'] = cosine_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar_data['cosine_distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edgar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.1.2. Vectorization\n",
    "<a id=\"4.1.2\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('pickle/AnnualReports_corpus.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(data.report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 0, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix =  tf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic\n",
    "https://medium.com/@adriensieg/text-similarities-da019229c894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
